{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "\n",
    "- \"Function calling\" refers to the capability of invoking specific functions or methods directly within the flow of interaction with a language model. \n",
    "- This feature allows for the execution of predefined functions or scripts in response to certain inputs or conditions identified by the language model during its processing. Essentially, it enables the language model to not only generate text-based responses but also to perform specific computational tasks, interact with external APIs, databases, or other software components, and then incorporate the results of these interactions into its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"\"\n",
    "open_ai_api_base = \"\"\n",
    "\n",
    "openai.api_base = open_ai_api_base\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    # Here we are passing only one function\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. Cincinnati, OH\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"], # Required parameter\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages to pass to the language model\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Cincinnati?\" # Something related to the function\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions \n",
    "    # function_call = \"auto\" : Auto determines that it automatically decides if it is going to use the function or not. Otherwise, we can use :\n",
    "    # none  : forces to not use the function.\n",
    "    # function_call = {\"name\": \"$NAME OF THE FUNCTION\"}\n",
    "    # New feature added by OpenAI that allows you to define custom functions (list of functions)\n",
    ")\n",
    "# OBS: If you force it to call a function and the content message has nothing to do with it, it will get confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x10907cc70> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"name\": \"get_current_weather\",\n",
       "    \"arguments\": \"{\\n  \\\"location\\\": \\\"Cincinnati, OH\\\"\\n}\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message[\"function_call\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Cincinnati, OH\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBS: \n",
    "- OpenAI models have token limits on them\n",
    "- You have to not only to be aware of the length of your messages, but also to the length of your functions\n",
    "- The size of the function—both in terms of its definition and its output—can significantly impact the token budget of a request. Here's why:\n",
    "    1) If the function definition needs to be included with each API request (for context or instruction to the model), it consumes part of the token limit. This is more relevant during the setup or if the function's logic is dynamically adjusted based on conversation flow.\n",
    "    2) The output of the function, when integrated into the conversation, also counts towards the token limit. If a function returns a large amount of text, it can quickly consume the available token budget, reducing the space for further interaction within the same API call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBS: OpenAI models have token limits on them\n",
    "# You have to not only to be aware of the length of your messages, but also to the length of your functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Cincinnati, OH'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = json.loads(response[\"choices\"][0][\"message\"]['function_call']['arguments'])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Cincinnati, OH\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = get_current_weather(args)\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather like in Cincinnati?\"}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\":\"function\",\n",
    "    \"name\":\"get_current_weather\",\n",
    "    \"content\":observation,\n",
    "    \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_customer_intent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
